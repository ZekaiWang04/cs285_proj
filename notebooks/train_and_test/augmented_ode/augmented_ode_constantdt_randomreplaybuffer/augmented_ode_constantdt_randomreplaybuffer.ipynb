{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from cs285.envs.pendulum.pendulum_env import PendulumEnv\n",
    "from cs285.envs.dt_sampler import ConstantSampler, UniformSampler, ExponentialSampler\n",
    "from cs285.infrastructure.replay_buffer import ReplayBufferTrajectories\n",
    "from cs285.infrastructure.utils import sample_n_trajectories, RandomPolicy\n",
    "from cs285.agents.ode_agent import ODEAgent\n",
    "from cs285.agents.nueral_ode import Base_NeuralODE, NeuralODE_Vanilla, Pendulum_True_Dynamics, NeuralODE_Augmented, NeuralODE_Latent_MLP, ODE_RNN\n",
    "from cs285.agents.utils import save_leaves, load_leaves\n",
    "from cs285.infrastructure import utils\n",
    "from cs285.scripts.notebook_utils import train, test\n",
    "from typing import Callable, Optional, Tuple, Sequence\n",
    "import numpy as np\n",
    "import gym\n",
    "from cs285.infrastructure import pytorch_util as ptu\n",
    "from tqdm import trange\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import diffrax\n",
    "from diffrax import diffeqsolve, Dopri5\n",
    "import optax\n",
    "import pickle\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_sampler = ConstantSampler(dt=0.05)\n",
    "mpc_dt_sampler = ConstantSampler(dt=0.05)\n",
    "env = PendulumEnv(dt_sampler=dt_sampler)\n",
    "\n",
    "agent_key, key = jax.random.split(key)\n",
    "neural_ode_name = \"augmented\"\n",
    "neural_ode_kwargs = {\n",
    "    \"ode_dt0\": 0.05,\n",
    "    \"mlp_dynamics_setup\": {\n",
    "        \"hidden_size\": 128,\n",
    "        \"num_layers\": 4,\n",
    "        \"activation\": \"tanh\",\n",
    "        \"output_activation\": \"identity\",\n",
    "    },\n",
    "    \"aug_dim\": 16,\n",
    "    \"aug_init_learnable\": True,\n",
    "}\n",
    "optimizer_name = \"adamw\"\n",
    "optimizer_kwargs = {\"learning_rate\": 1e-3}\n",
    "mb_agent = ODEAgent(\n",
    "    env=env,\n",
    "    key=agent_key,\n",
    "    neural_ode_name=neural_ode_name,\n",
    "    neural_ode_kwargs=neural_ode_kwargs,\n",
    "    optimizer_name=optimizer_name,\n",
    "    optimizer_kwargs=optimizer_kwargs,\n",
    "    ensemble_size=1,\n",
    "    train_discount=1,\n",
    "    mpc_horizon_steps=20,\n",
    "    mpc_dt_sampler=mpc_dt_sampler,\n",
    "    mpc_strategy=\"random\",\n",
    "    mpc_discount=0.95,\n",
    "    mpc_num_action_sequences=1000,\n",
    "    cem_num_iters=4,\n",
    "    cem_num_elites=5,\n",
    "    cem_alpha=1,\n",
    ")\n",
    "with open(\"../../../reply_buffers/random_constant_0.05_replay_buffer\", \"rb\") as f:\n",
    "    replay_buffer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = {\n",
    "    \"batch_size\": 64,\n",
    "    \"steps\": 1000,\n",
    "    \"ep_len\": 20,\n",
    "    \"stride\": 1,\n",
    "    \"discount\": 1.0,\n",
    "}\n",
    "train_key, key = jax.random.split(key)\n",
    "mb_agent, losses = train(mb_agent, 0, replay_buffer, train_config, key=train_key)\n",
    "save_leaves(mb_agent, \"agent\")\n",
    "with open(\"train_losses\", \"wb\") as f:\n",
    "    pickle.dump(losses, f)\n",
    "test_key, key = jax.random.split(key)\n",
    "rewards, stats = test(mb_agent, 10, key=test_key, plot=True)\n",
    "with open(\"eval_stats\", \"wb\") as f:\n",
    "    pickle.dump(stats, f)\n",
    "with open(\"eval_rewards\", \"wb\") as f:\n",
    "    pickle.dump(rewards, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs285_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
