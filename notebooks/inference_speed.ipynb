{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler\n",
    "from cs285.envs.pendulum.pendulum_env import PendulumEnv\n",
    "from cs285.envs.dt_sampler import ConstantSampler\n",
    "from cs285.infrastructure.replay_buffer import ReplayBufferTrajectories\n",
    "from cs285.infrastructure.utils import sample_n_trajectories, RandomPolicy\n",
    "from typing import Callable, Optional, Tuple, Sequence\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import gym\n",
    "from cs285.infrastructure import pytorch_util as ptu\n",
    "from torchdiffeq import odeint\n",
    "from tqdm import trange\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import diffrax\n",
    "from diffrax import diffeqsolve, Dopri5\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralODE_jax(eqx.Module):\n",
    "    _str_to_activation = {\n",
    "        \"relu\": jax.nn.relu,\n",
    "        \"tanh\": jax.nn.tanh,\n",
    "        \"leaky_relu\": jax.nn.leaky_relu,\n",
    "        \"sigmoid\": jax.nn.sigmoid,\n",
    "        \"selu\": jax.nn.selu,\n",
    "        \"softplus\": jax.nn.softplus,\n",
    "        \"identity\": lambda x: x,\n",
    "    }\n",
    "    mlp: eqx.nn.MLP\n",
    "    def __init__(\n",
    "            self,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            ob_dim,\n",
    "            ac_dim,\n",
    "            key,\n",
    "            activation=\"relu\",\n",
    "            output_activation=\"identity\",\n",
    "        ):\n",
    "        super().__init__()\n",
    "        activation = self._str_to_activation[activation]\n",
    "        output_activation = self._str_to_activation[output_activation]\n",
    "        # hidden_size is an integer\n",
    "        self.mlp = eqx.nn.MLP(in_size=ob_dim+ac_dim,\n",
    "                              out_size=ob_dim,\n",
    "                              width_size=hidden_size,\n",
    "                              depth=num_layers,\n",
    "                              activation=activation,\n",
    "                              final_activation=output_activation,\n",
    "                              key=key)\n",
    "\n",
    "    @jax.jit\n",
    "    def __call__(self, t, y, args):\n",
    "        # args is a dictionary that contains times and actions\n",
    "        times = args[\"times\"] # (ep_len,)\n",
    "        actions = args[\"actions\"] # (ep_len, ac_dim)\n",
    "        idx = jnp.searchsorted(times, t, side=\"right\") - 1\n",
    "        action = actions[idx] # (ac_dim)\n",
    "        # althoug I believe this should also work for batched \n",
    "        return self.mlp(jnp.concatenate((y, action), axis=-1))\n",
    "    \n",
    "class ODEAgent_jax():\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        key,\n",
    "        hidden_size: int,\n",
    "        num_layers: int,\n",
    "        ensemble_size: int,\n",
    "        train_timestep: float,\n",
    "        mpc_horizon_steps: int,\n",
    "        mpc_timestep: float,\n",
    "        mpc_strategy: str,\n",
    "        mpc_num_action_sequences: int,\n",
    "        cem_num_iters: Optional[int] = None,\n",
    "        cem_num_elites: Optional[int] = None,\n",
    "        cem_alpha: Optional[float] = None,\n",
    "        activation: str = \"relu\",\n",
    "        output_activation: str = \"identity\",\n",
    "        lr: float=0.001\n",
    "    ):\n",
    "        # super().__init__()\n",
    "        self.env = env\n",
    "        self.train_timestep = train_timestep\n",
    "        self.mpc_horizon_steps = mpc_horizon_steps # in terms of timesteps\n",
    "        self.mpc_strategy = mpc_strategy\n",
    "        self.mpc_num_action_sequences = mpc_num_action_sequences\n",
    "        self.cem_num_iters = cem_num_iters\n",
    "        self.cem_num_elites = cem_num_elites\n",
    "        self.cem_alpha = cem_alpha\n",
    "        self.mpc_timestep = mpc_timestep # when evaluating\n",
    "\n",
    "        assert mpc_strategy in (\n",
    "            \"random\",\n",
    "            \"cem\",\n",
    "        ), f\"'{mpc_strategy}' is not a valid MPC strategy\"\n",
    "\n",
    "        # ensure the environment is state-based\n",
    "        assert len(env.observation_space.shape) == 1\n",
    "        assert len(env.action_space.shape) == 1\n",
    "\n",
    "        self.ob_dim = env.observation_space.shape[0]\n",
    "        self.ac_dim = env.action_space.shape[0]\n",
    "\n",
    "        self.ensemble_size = ensemble_size\n",
    "        keys = jax.random.split(key, ensemble_size)\n",
    "        self.ode_functions = [NeuralODE_jax(\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            ob_dim=self.ob_dim,\n",
    "            ac_dim=self.ac_dim,\n",
    "            activation=activation,\n",
    "            output_activation=output_activation,\n",
    "            key = keys[n]\n",
    "            ) for n in range(ensemble_size)]\n",
    "        self.optims = [optax.adamw(lr) for _ in range(ensemble_size)]\n",
    "        self.optim_states = [self.optims[n].init(eqx.filter(self.ode_functions[n].mlp, eqx.is_array)) for n in range(self.ensemble_size)]\n",
    "\n",
    "        self.solver = Dopri5()\n",
    "    \n",
    "    def update(self, i: int, obs: np.ndarray, acs: np.ndarray, times: np.ndarray):\n",
    "        \"\"\"\n",
    "        Update self.dynamics_models[i] using the given trajectory\n",
    "\n",
    "        Args:\n",
    "            i: index of the dynamics model to update\n",
    "            obs: (ep_len, ob_dim)\n",
    "            acs: (ep_len, ac_dim)\n",
    "            times: (ep_len)\n",
    "        \"\"\"\n",
    "        @eqx.filter_value_and_grad\n",
    "        def loss_grad(ode_func):\n",
    "            sol = diffeqsolve(\n",
    "                diffrax.ODETerm(ode_func), \n",
    "                self.solver, \n",
    "                t0=times[0], \n",
    "                t1=times[-1], \n",
    "                dt0=self.train_timestep,\n",
    "                y0 = obs[0, :],\n",
    "                args={\"times\": times, \"actions\": acs},\n",
    "                saveat=diffrax.SaveAt(ts=times)\n",
    "            )\n",
    "            assert sol.ys.shape == obs.shape\n",
    "            return jnp.mean((sol.ys - obs) ** 2) # do we want a  \"discount\"-like trick\n",
    "\n",
    "        @eqx.filter_jit\n",
    "        def make_step(ode_func, optim, opt_state):\n",
    "            loss, grad = loss_grad(ode_func)\n",
    "            updates, opt_state = optim.update(grad, opt_state)\n",
    "            ode_func = eqx.apply_updates(ode_func, updates)\n",
    "            return loss, ode_func, opt_state\n",
    "        \n",
    "        ode_func, optim, opt_state = self.ode_functions[i], self.optims[i], self.optim_states[i]\n",
    "        loss, ode_func, opt_state = make_step(ode_func, optim, opt_state)\n",
    "        self.ode_functions[i], self.optim_states[i] = ode_func, opt_state\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 55.33it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret value of type <class 'jax._src.custom_derivatives.custom_jvp'> as an abstract array; it does not have a dtype attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/jax/_src/api_util.py:582\u001b[0m, in \u001b[0;36mshaped_abstractify\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 582\u001b[0m   \u001b[39mreturn\u001b[39;00m _shaped_abstractify_handlers[\u001b[39mtype\u001b[39;49m(x)](x)\n\u001b[1;32m    583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: <class 'jax._src.custom_derivatives.custom_jvp'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(mb_agent_jas\u001b[39m.\u001b[39mensemble_size):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     traj \u001b[39m=\u001b[39m replay_buffer\u001b[39m.\u001b[39msample_rollout()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     mb_agent_jas\u001b[39m.\u001b[39;49mupdate(i, traj[\u001b[39m\"\u001b[39;49m\u001b[39mobservations\u001b[39;49m\u001b[39m\"\u001b[39;49m], traj[\u001b[39m\"\u001b[39;49m\u001b[39mactions\u001b[39;49m\u001b[39m\"\u001b[39;49m], jnp\u001b[39m.\u001b[39;49mcumsum(traj[\u001b[39m\"\u001b[39;49m\u001b[39mdts\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n",
      "\u001b[1;32m/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m loss, ode_func, opt_state\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m ode_func, optim, opt_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mode_functions[i], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptims[i], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_states[i]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m loss, ode_func, opt_state \u001b[39m=\u001b[39m make_step(ode_func, optim, opt_state)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mode_functions[i], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_states[i] \u001b[39m=\u001b[39m ode_func, opt_state\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mitem()\n",
      "    \u001b[0;31m[... skipping hidden 16 frame]\u001b[0m\n",
      "\u001b[1;32m/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m \u001b[39m@eqx\u001b[39m\u001b[39m.\u001b[39mfilter_jit\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_step\u001b[39m(ode_func, optim, opt_state):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m     loss, grad \u001b[39m=\u001b[39m loss_grad(ode_func)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m     updates, opt_state \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mupdate(grad, opt_state)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m     ode_func \u001b[39m=\u001b[39m eqx\u001b[39m.\u001b[39mapply_updates(ode_func, updates)\n",
      "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "\u001b[1;32m/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m \u001b[39m@eqx\u001b[39m\u001b[39m.\u001b[39mfilter_value_and_grad\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_grad\u001b[39m(ode_func):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m     sol \u001b[39m=\u001b[39m diffeqsolve(\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m         diffrax\u001b[39m.\u001b[39;49mODETerm(ode_func), \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msolver, \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m         t0\u001b[39m=\u001b[39;49mtimes[\u001b[39m0\u001b[39;49m], \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m         t1\u001b[39m=\u001b[39;49mtimes[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m         dt0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_timestep,\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m         y0 \u001b[39m=\u001b[39;49m obs[\u001b[39m0\u001b[39;49m, :],\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m         args\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mtimes\u001b[39;49m\u001b[39m\"\u001b[39;49m: times, \u001b[39m\"\u001b[39;49m\u001b[39mactions\u001b[39;49m\u001b[39m\"\u001b[39;49m: acs},\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m         saveat\u001b[39m=\u001b[39;49mdiffrax\u001b[39m.\u001b[39;49mSaveAt(ts\u001b[39m=\u001b[39;49mtimes)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m     )\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m     \u001b[39massert\u001b[39;00m sol\u001b[39m.\u001b[39mys\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m obs\u001b[39m.\u001b[39mshape\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/zekai/repos/cs285_proj/notebooks/inference_speed.ipynb#X35sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39mmean((sol\u001b[39m.\u001b[39mys \u001b[39m-\u001b[39m obs) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 16 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/diffrax/integrate.py:823\u001b[0m, in \u001b[0;36mdiffeqsolve\u001b[0;34m(terms, solver, t0, t1, dt0, y0, args, saveat, stepsize_controller, adjoint, discrete_terminating_event, max_steps, throw, solver_state, controller_state, made_jump)\u001b[0m\n\u001b[1;32m    802\u001b[0m init_state \u001b[39m=\u001b[39m State(\n\u001b[1;32m    803\u001b[0m     y\u001b[39m=\u001b[39my0,\n\u001b[1;32m    804\u001b[0m     tprev\u001b[39m=\u001b[39mtprev,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    816\u001b[0m     dense_save_index\u001b[39m=\u001b[39mdense_save_index,\n\u001b[1;32m    817\u001b[0m )\n\u001b[1;32m    819\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \u001b[39m# Main loop\u001b[39;00m\n\u001b[1;32m    821\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m final_state, aux_stats \u001b[39m=\u001b[39m adjoint\u001b[39m.\u001b[39;49mloop(\n\u001b[1;32m    824\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    825\u001b[0m     terms\u001b[39m=\u001b[39;49mterms,\n\u001b[1;32m    826\u001b[0m     solver\u001b[39m=\u001b[39;49msolver,\n\u001b[1;32m    827\u001b[0m     stepsize_controller\u001b[39m=\u001b[39;49mstepsize_controller,\n\u001b[1;32m    828\u001b[0m     discrete_terminating_event\u001b[39m=\u001b[39;49mdiscrete_terminating_event,\n\u001b[1;32m    829\u001b[0m     saveat\u001b[39m=\u001b[39;49msaveat,\n\u001b[1;32m    830\u001b[0m     t0\u001b[39m=\u001b[39;49mt0,\n\u001b[1;32m    831\u001b[0m     t1\u001b[39m=\u001b[39;49mt1,\n\u001b[1;32m    832\u001b[0m     dt0\u001b[39m=\u001b[39;49mdt0,\n\u001b[1;32m    833\u001b[0m     max_steps\u001b[39m=\u001b[39;49mmax_steps,\n\u001b[1;32m    834\u001b[0m     init_state\u001b[39m=\u001b[39;49minit_state,\n\u001b[1;32m    835\u001b[0m     throw\u001b[39m=\u001b[39;49mthrow,\n\u001b[1;32m    836\u001b[0m     passed_solver_state\u001b[39m=\u001b[39;49mpassed_solver_state,\n\u001b[1;32m    837\u001b[0m     passed_controller_state\u001b[39m=\u001b[39;49mpassed_controller_state,\n\u001b[1;32m    838\u001b[0m )\n\u001b[1;32m    840\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[39m# Finish up\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    844\u001b[0m is_save_state \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39misinstance\u001b[39m(x, SaveState)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/diffrax/adjoint.py:286\u001b[0m, in \u001b[0;36mRecursiveCheckpointAdjoint.loop\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    282\u001b[0m     outer_while_loop \u001b[39m=\u001b[39m ft\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m    283\u001b[0m         _outer_loop, kind\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcheckpointed\u001b[39m\u001b[39m\"\u001b[39m, checkpoints\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoints\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m final_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_loop(\n\u001b[1;32m    287\u001b[0m     terms\u001b[39m=\u001b[39;49mterms,\n\u001b[1;32m    288\u001b[0m     saveat\u001b[39m=\u001b[39;49msaveat,\n\u001b[1;32m    289\u001b[0m     init_state\u001b[39m=\u001b[39;49minit_state,\n\u001b[1;32m    290\u001b[0m     max_steps\u001b[39m=\u001b[39;49mmax_steps,\n\u001b[1;32m    291\u001b[0m     inner_while_loop\u001b[39m=\u001b[39;49minner_while_loop,\n\u001b[1;32m    292\u001b[0m     outer_while_loop\u001b[39m=\u001b[39;49mouter_while_loop,\n\u001b[1;32m    293\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    294\u001b[0m )\n\u001b[1;32m    295\u001b[0m \u001b[39mif\u001b[39;00m msg \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     final_state \u001b[39m=\u001b[39m eqxi\u001b[39m.\u001b[39mnondifferentiable_backward(\n\u001b[1;32m    297\u001b[0m         final_state, msg\u001b[39m=\u001b[39mmsg, symbolic\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/diffrax/integrate.py:423\u001b[0m, in \u001b[0;36mloop\u001b[0;34m(solver, stepsize_controller, discrete_terminating_event, saveat, t0, t1, dt0, max_steps, terms, args, init_state, inner_while_loop, outer_while_loop)\u001b[0m\n\u001b[1;32m    421\u001b[0m static_made_jump \u001b[39m=\u001b[39m init_state\u001b[39m.\u001b[39mmade_jump\n\u001b[1;32m    422\u001b[0m static_result \u001b[39m=\u001b[39m init_state\u001b[39m.\u001b[39mresult\n\u001b[0;32m--> 423\u001b[0m filter_state \u001b[39m=\u001b[39m eqx\u001b[39m.\u001b[39;49mfilter_eval_shape(body_fun, init_state)\n\u001b[1;32m    424\u001b[0m _filtering \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    425\u001b[0m static_made_jump \u001b[39m=\u001b[39m filter_state\u001b[39m.\u001b[39mmade_jump\n",
      "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/diffrax/integrate.py:219\u001b[0m, in \u001b[0;36mloop.<locals>.body_fun\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    212\u001b[0m state \u001b[39m=\u001b[39m _handle_static(state)\n\u001b[1;32m    214\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[39m# Actually do some differential equation solving! Make numerical steps, adapt\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[39m# step sizes, all that jazz.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m (y, y_error, dense_info, solver_state, solver_result) \u001b[39m=\u001b[39m solver\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m    220\u001b[0m     terms,\n\u001b[1;32m    221\u001b[0m     state\u001b[39m.\u001b[39;49mtprev,\n\u001b[1;32m    222\u001b[0m     state\u001b[39m.\u001b[39;49mtnext,\n\u001b[1;32m    223\u001b[0m     state\u001b[39m.\u001b[39;49my,\n\u001b[1;32m    224\u001b[0m     args,\n\u001b[1;32m    225\u001b[0m     state\u001b[39m.\u001b[39;49msolver_state,\n\u001b[1;32m    226\u001b[0m     state\u001b[39m.\u001b[39;49mmade_jump,\n\u001b[1;32m    227\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[39m# e.g. if someone has a sqrt(y) in the vector field, and dt0 is so large that\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[39m# we get a negative value for y, and then get a NaN vector field. (And then\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m# everything breaks.) See #143.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m y_error \u001b[39m=\u001b[39m jtu\u001b[39m.\u001b[39mtree_map(\u001b[39mlambda\u001b[39;00m x: jnp\u001b[39m.\u001b[39mwhere(jnp\u001b[39m.\u001b[39misnan(x), jnp\u001b[39m.\u001b[39minf, x), y_error)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/diffrax/solver/runge_kutta.py:1041\u001b[0m, in \u001b[0;36mAbstractRungeKutta.step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1025\u001b[0m init_val \u001b[39m=\u001b[39m (\n\u001b[1;32m   1026\u001b[0m     init_stage_index,\n\u001b[1;32m   1027\u001b[0m     y0,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1033\u001b[0m     RESULTS\u001b[39m.\u001b[39msuccessful,\n\u001b[1;32m   1034\u001b[0m )\n\u001b[1;32m   1035\u001b[0m \u001b[39m# Needs to be an `eqxi.while_loop` as:\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[39m# (a) we may have variable length: e.g. an FSAL explicit RK scheme will have one\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[39m#     more stage on the first step.\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39m# (b) to work around a limitation of JAX's autodiff being unable to express\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39m#     \"triangular computations\" (every stage depends on all previous stages)\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[39m#     without spurious copies.\u001b[39;00m\n\u001b[0;32m-> 1041\u001b[0m final_val \u001b[39m=\u001b[39m eqxi\u001b[39m.\u001b[39;49mwhile_loop(\n\u001b[1;32m   1042\u001b[0m     cond_stage,\n\u001b[1;32m   1043\u001b[0m     rk_stage,\n\u001b[1;32m   1044\u001b[0m     init_val,\n\u001b[1;32m   1045\u001b[0m     max_steps\u001b[39m=\u001b[39;49mnum_stages,\n\u001b[1;32m   1046\u001b[0m     buffers\u001b[39m=\u001b[39;49mbuffers,\n\u001b[1;32m   1047\u001b[0m     kind\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcheckpointed\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_kind \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_kind,\n\u001b[1;32m   1048\u001b[0m     checkpoints\u001b[39m=\u001b[39;49mnum_stages,\n\u001b[1;32m   1049\u001b[0m     base\u001b[39m=\u001b[39;49mnum_stages,\n\u001b[1;32m   1050\u001b[0m )\n\u001b[1;32m   1051\u001b[0m _, y1, f1_for_fsal, _, _, fs, ks, result \u001b[39m=\u001b[39m final_val\n\u001b[1;32m   1053\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[39m# Calculate outputs: the final `y1` from our step, any dense information, etc.\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39m#\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/equinox/internal/_loop/loop.py:107\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39melif\u001b[39;00m kind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcheckpointed\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    106\u001b[0m     \u001b[39mdel\u001b[39;00m kind, base\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mreturn\u001b[39;00m checkpointed_while_loop(\n\u001b[1;32m    108\u001b[0m         cond_fun,\n\u001b[1;32m    109\u001b[0m         body_fun,\n\u001b[1;32m    110\u001b[0m         init_val,\n\u001b[1;32m    111\u001b[0m         max_steps\u001b[39m=\u001b[39;49mmax_steps,\n\u001b[1;32m    112\u001b[0m         buffers\u001b[39m=\u001b[39;49mbuffers,\n\u001b[1;32m    113\u001b[0m         checkpoints\u001b[39m=\u001b[39;49mcheckpoints,\n\u001b[1;32m    114\u001b[0m     )\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m kind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbounded\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    116\u001b[0m     \u001b[39mdel\u001b[39;00m kind, checkpoints\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/equinox/internal/_loop/checkpointed.py:247\u001b[0m, in \u001b[0;36mcheckpointed_while_loop\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    245\u001b[0m cond_fun_ \u001b[39m=\u001b[39m filter_closure_convert(cond_fun_, init_val_)\n\u001b[1;32m    246\u001b[0m cond_fun_ \u001b[39m=\u001b[39m jtu\u001b[39m.\u001b[39mtree_map(_stop_gradient, cond_fun_)\n\u001b[0;32m--> 247\u001b[0m body_fun_ \u001b[39m=\u001b[39m filter_closure_convert(body_fun_, init_val_)\n\u001b[1;32m    248\u001b[0m vjp_arg \u001b[39m=\u001b[39m (init_val_, body_fun_)\n\u001b[1;32m    249\u001b[0m _, _, _, final_val \u001b[39m=\u001b[39m _checkpointed_while_loop(\n\u001b[1;32m    250\u001b[0m     vjp_arg, cond_fun_, checkpoints, buffers_, max_steps\n\u001b[1;32m    251\u001b[0m )\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/equinox/internal/_loop/common.py:451\u001b[0m, in \u001b[0;36mcommon_rewrite.<locals>.new_body_fun\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m    449\u001b[0m step, pred, _, val \u001b[39m=\u001b[39m val\n\u001b[1;32m    450\u001b[0m buffer_val \u001b[39m=\u001b[39m _wrap_buffers(val, pred, tag)\n\u001b[0;32m--> 451\u001b[0m buffer_val2 \u001b[39m=\u001b[39m body_fun(buffer_val)\n\u001b[1;32m    452\u001b[0m \u001b[39m# Needed to work with `disable_jit`, as then we lose the automatic\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m# ArrayLike->Array cast provided by JAX's while loops.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39m# The input `val` is already cast to Array below, so this matches that.\u001b[39;00m\n\u001b[1;32m    455\u001b[0m buffer_val2 \u001b[39m=\u001b[39m jtu\u001b[39m.\u001b[39mtree_map(fixed_asarray, buffer_val2)\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/diffrax/solver/runge_kutta.py:935\u001b[0m, in \u001b[0;36mAbstractRungeKutta.step.<locals>.rk_stage\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m vf_expensive\n\u001b[1;32m    934\u001b[0m \u001b[39massert\u001b[39;00m implicit_fi \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _unused\n\u001b[0;32m--> 935\u001b[0m fi \u001b[39m=\u001b[39m vf(ti, yi, implicit_val\u001b[39m=\u001b[39;49mimplicit_fi)\n\u001b[1;32m    936\u001b[0m \u001b[39mif\u001b[39;00m store_fs:\n\u001b[1;32m    937\u001b[0m     ki \u001b[39m=\u001b[39m _unused\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/diffrax/solver/runge_kutta.py:597\u001b[0m, in \u001b[0;36mAbstractRungeKutta.step.<locals>.vf\u001b[0;34m(t, y, implicit_val)\u001b[0m\n\u001b[1;32m    595\u001b[0m _assert_same_structure(y, y0)\n\u001b[1;32m    596\u001b[0m _vf \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m term_i, t_i: term_i\u001b[39m.\u001b[39mvf(t_i, y, args)\n\u001b[0;32m--> 597\u001b[0m out \u001b[39m=\u001b[39m t_map(_vf, terms, t, implicit_val\u001b[39m=\u001b[39;49mimplicit_val)\n\u001b[1;32m    598\u001b[0m \u001b[39mif\u001b[39;00m f0 \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _unused:\n\u001b[1;32m    599\u001b[0m     _assert_same_structure(out, f0)\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/diffrax/solver/runge_kutta.py:550\u001b[0m, in \u001b[0;36mAbstractRungeKutta.step.<locals>.t_map\u001b[0;34m(fn, implicit_val, *trees)\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39m_trees)\n\u001b[0;32m--> 550\u001b[0m \u001b[39mreturn\u001b[39;00m jtu\u001b[39m.\u001b[39;49mtree_map(_fn, tableaus, \u001b[39m*\u001b[39;49mtrees)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/diffrax/solver/runge_kutta.py:548\u001b[0m, in \u001b[0;36mAbstractRungeKutta.step.<locals>.t_map.<locals>._fn\u001b[0;34m(tableau, *_trees)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[39mreturn\u001b[39;00m implicit_val\n\u001b[1;32m    547\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 548\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49m_trees)\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/diffrax/solver/runge_kutta.py:596\u001b[0m, in \u001b[0;36mAbstractRungeKutta.step.<locals>.vf.<locals>.<lambda>\u001b[0;34m(term_i, t_i)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvf\u001b[39m(t, y, \u001b[39m*\u001b[39m, implicit_val):\n\u001b[1;32m    595\u001b[0m     _assert_same_structure(y, y0)\n\u001b[0;32m--> 596\u001b[0m     _vf \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m term_i, t_i: term_i\u001b[39m.\u001b[39;49mvf(t_i, y, args)\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m t_map(_vf, terms, t, implicit_val\u001b[39m=\u001b[39mimplicit_val)\n\u001b[1;32m    598\u001b[0m     \u001b[39mif\u001b[39;00m f0 \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _unused:\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/diffrax/term.py:391\u001b[0m, in \u001b[0;36mWrapTerm.vf\u001b[0;34m(self, t, y, args)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvf\u001b[39m(\u001b[39mself\u001b[39m, t: Scalar, y: PyTree, args: PyTree) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PyTree:\n\u001b[1;32m    390\u001b[0m     t \u001b[39m=\u001b[39m t \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdirection\n\u001b[0;32m--> 391\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mterm\u001b[39m.\u001b[39;49mvf(t, y, args)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/diffrax/term.py:173\u001b[0m, in \u001b[0;36mODETerm.vf\u001b[0;34m(self, t, y, args)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvf\u001b[39m(\u001b[39mself\u001b[39m, t: Scalar, y: PyTree, args: PyTree) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PyTree:\n\u001b[0;32m--> 173\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvector_field(t, y, args)\n\u001b[1;32m    174\u001b[0m     \u001b[39mif\u001b[39;00m jtu\u001b[39m.\u001b[39mtree_structure(out) \u001b[39m!=\u001b[39m jtu\u001b[39m.\u001b[39mtree_structure(y):\n\u001b[1;32m    175\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    176\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe vector field inside `ODETerm` must return a pytree with the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39msame structure as `y0`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    178\u001b[0m         )\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs285_proj/lib/python3.9/site-packages/jax/_src/api_util.py:573\u001b[0m, in \u001b[0;36m_shaped_abstractify_slow\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    571\u001b[0m   dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mcanonicalize_dtype(x\u001b[39m.\u001b[39mdtype, allow_extended_dtype\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    572\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 573\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot interpret value of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(x)\u001b[39m}\u001b[39;00m\u001b[39m as an abstract array; it \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mdoes not have a dtype attribute\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[39mreturn\u001b[39;00m core\u001b[39m.\u001b[39mShapedArray(np\u001b[39m.\u001b[39mshape(x), dtype, weak_type\u001b[39m=\u001b[39mweak_type,\n\u001b[1;32m    577\u001b[0m                         named_shape\u001b[39m=\u001b[39mnamed_shape)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret value of type <class 'jax._src.custom_derivatives.custom_jvp'> as an abstract array; it does not have a dtype attribute"
     ]
    }
   ],
   "source": [
    "dt_sampler = ConstantSampler(dt=0.05)\n",
    "env = PendulumEnv(\n",
    "    dt_sampler=dt_sampler\n",
    ")\n",
    "mb_agent_jas = ODEAgent_jax(\n",
    "    env=env,\n",
    "    hidden_size=128,\n",
    "    num_layers=4,\n",
    "    ensemble_size=10,\n",
    "    train_timestep=0.005,\n",
    "    mpc_horizon_steps=100,\n",
    "    mpc_timestep=0.005,\n",
    "    mpc_strategy=\"random\",\n",
    "    mpc_num_action_sequences=10,\n",
    "    key=key\n",
    ")\n",
    "replay_buffer = ReplayBufferTrajectories(seed=0)\n",
    "trajs, _ = sample_n_trajectories(env, RandomPolicy(env=env), ntraj=10, max_length=200)\n",
    "replay_buffer.add_rollouts(trajs)\n",
    "\n",
    "for n in trange(1000):\n",
    "    for i in range(mb_agent_jas.ensemble_size):\n",
    "        traj = replay_buffer.sample_rollout()\n",
    "        mb_agent_jas.update(i, traj[\"observations\"], traj[\"actions\"], jnp.cumsum(traj[\"dts\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralODE(nn.Module):\n",
    "    _str_to_activation = {\n",
    "        \"relu\": nn.ReLU(),\n",
    "        \"tanh\": nn.Tanh(),\n",
    "        \"leaky_relu\": nn.LeakyReLU(),\n",
    "        \"sigmoid\": nn.Sigmoid(),\n",
    "        \"selu\": nn.SELU(),\n",
    "        \"softplus\": nn.Softplus(),\n",
    "        \"identity\": nn.Identity(),\n",
    "    }\n",
    "    def __init__(self, hidden_dims, ob_dim, ac_dim, activation=\"relu\", output_activation='identity'):\n",
    "        super().__init__()\n",
    "        self.ac_dim = ac_dim\n",
    "        self.ob_dim = ob_dim\n",
    "        activation = self._str_to_activation[activation]\n",
    "        output_activation = self._str_to_activation[output_activation]\n",
    "        layers = []\n",
    "        hidden_dims = [ob_dim + ac_dim] + hidden_dims\n",
    "        for n in range(len(hidden_dims) - 1):\n",
    "            layers.append(nn.Linear(hidden_dims[n], hidden_dims[n+1]))\n",
    "            layers.append(activation)\n",
    "        layers.append(nn.Linear(hidden_dims[-1], ob_dim))\n",
    "        layers.append(output_activation)\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.1)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "    \n",
    "    def update_action(self, actions: torch.Tensor, times: torch.Tensor):\n",
    "        ep_len = actions.shape[0]\n",
    "        assert actions.shape == (ep_len, self.ac_dim) and times.shape == (ep_len,)\n",
    "        # times = times - times[0] # start with t=0\n",
    "        # right now, do not assume t0 = 0\n",
    "        self.register_buffer(\"times\", times)\n",
    "        self.register_buffer(\"actions\", actions)\n",
    "\n",
    "    def _get_action(self, t):\n",
    "        idx = torch.searchsorted(self.times, t, right=True) - 1\n",
    "        return self.actions[idx]\n",
    "\n",
    "    def forward(self, t, y):\n",
    "        ac = self._get_action(t)\n",
    "        return self.net(torch.cat((y, ac), dim=-1))\n",
    "\n",
    "    \n",
    "class ODEAgent(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: gym.Env,\n",
    "        hidden_dims: Sequence[int],\n",
    "        make_optimizer: Callable[[nn.ParameterList], torch.optim.Optimizer],\n",
    "        ensemble_size: int,\n",
    "        mpc_horizon_steps: int,\n",
    "        mpc_timestep: float,\n",
    "        mpc_strategy: str,\n",
    "        mpc_num_action_sequences: int,\n",
    "        cem_num_iters: Optional[int] = None,\n",
    "        cem_num_elites: Optional[int] = None,\n",
    "        cem_alpha: Optional[float] = None,\n",
    "        activation: str = \"relu\",\n",
    "        output_activation: str = \"identity\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.env = env\n",
    "        self.mpc_horizon_steps = mpc_horizon_steps # in terms of timesteps\n",
    "        self.mpc_strategy = mpc_strategy\n",
    "        self.mpc_num_action_sequences = mpc_num_action_sequences\n",
    "        self.cem_num_iters = cem_num_iters\n",
    "        self.cem_num_elites = cem_num_elites\n",
    "        self.cem_alpha = cem_alpha\n",
    "        self.mpc_timestep = mpc_timestep # when evaluating\n",
    "\n",
    "        assert mpc_strategy in (\n",
    "            \"random\",\n",
    "            \"cem\",\n",
    "        ), f\"'{mpc_strategy}' is not a valid MPC strategy\"\n",
    "\n",
    "        # ensure the environment is state-based\n",
    "        assert len(env.observation_space.shape) == 1\n",
    "        assert len(env.action_space.shape) == 1\n",
    "\n",
    "        self.ob_dim = env.observation_space.shape[0]\n",
    "        self.ac_dim = env.action_space.shape[0]\n",
    "\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.ode_functions = nn.ModuleList(\n",
    "            [\n",
    "                NeuralODE(\n",
    "                    hidden_dims,\n",
    "                    self.ob_dim,\n",
    "                    self.ac_dim,\n",
    "                    activation,\n",
    "                    output_activation\n",
    "                ).to(ptu.device)\n",
    "                for _ in range(ensemble_size)\n",
    "            ]\n",
    "        )\n",
    "        self.optimizer = make_optimizer(self.ode_functions.parameters())\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    def update(self, i: int, obs: np.ndarray, acs: np.ndarray, times: np.ndarray):\n",
    "        \"\"\"\n",
    "        Update self.dynamics_models[i] using the given trajectory\n",
    "\n",
    "        Args:\n",
    "            i: index of the dynamics model to update\n",
    "            obs: (ep_len, ob_dim)\n",
    "            acs: (ep_len, ac_dim)\n",
    "            times: (ep_len)\n",
    "        \"\"\"\n",
    "        obs = ptu.from_numpy(obs)\n",
    "        acs = ptu.from_numpy(acs)\n",
    "        times = ptu.from_numpy(times)\n",
    "        ode_func = self.ode_functions[i]\n",
    "        ode_func.update_action(acs, times)\n",
    "        ode_out = odeint(ode_func, obs[0, :], times) # t0 = times[0] in torchdiffeq\n",
    "        # possible problem: the ode function is only \"evaluating\" on times\n",
    "        # I am not sure whether there is an implicit dt or dt[i] = times[i+1] - times[i]\n",
    "        # I know for diffrax in jax, there is a separate dt argument passed into odeint()\n",
    "        assert ode_out.shape == obs.shape\n",
    "        loss = self.loss_fn(ode_out, obs)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return ptu.to_numpy(loss)\n",
    "    \n",
    "    def update_statistics(self, **kwargs):\n",
    "        pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate_action_sequences(self, obs: np.ndarray, acs: np.ndarray):\n",
    "        obs = ptu.from_numpy(obs) # (ob_dim)\n",
    "        acs_np = acs\n",
    "        acs = ptu.from_numpy(acs) # (N, steps, ac_dim)\n",
    "        times = torch.linspace(0, (self.mpc_horizon_steps - 1) * self.mpc_timestep, self.mpc_horizon_steps, device=ptu.device)\n",
    "        reward_arr = np.zeros((self.mpc_num_action_sequences, self.ensemble_size))\n",
    "        for n in range(self.mpc_num_action_sequences):\n",
    "            for i in range(self.ensemble_size):\n",
    "                ode_func = self.ode_functions[i]\n",
    "                ode_func.update_action(acs[n, :, :], times)\n",
    "                ode_out = odeint(ode_func, obs, times) # (steps, ob_dim)\n",
    "                rewards, _ = self.env.get_reward(ptu.to_numpy(ode_out), acs_np[n, :, :])\n",
    "                avg_reward = np.mean(rewards)\n",
    "                reward_arr[n, i] = avg_reward\n",
    "        return np.mean(reward_arr, axis=1)\n",
    "    # maybe I should manually implement batched Euler solver\n",
    "    # to make inference faster\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_action(self, obs: np.ndarray):\n",
    "        \"\"\"\n",
    "        Choose the best action using model-predictive control.\n",
    "\n",
    "        Args:\n",
    "            obs: (ob_dim,)\n",
    "        \"\"\"\n",
    "        # always start with uniformly random actions\n",
    "        actions = np.random.uniform(\n",
    "            self.env.action_space.low,\n",
    "            self.env.action_space.high,\n",
    "            size=(self.mpc_num_action_sequences, self.mpc_horizon_steps, self.ac_dim),\n",
    "        )\n",
    "\n",
    "        if self.mpc_strategy == \"random\":\n",
    "            # evaluate each action sequence and return the best one\n",
    "            rewards = self.evaluate_action_sequences(obs, actions)\n",
    "            assert rewards.shape == (self.mpc_num_action_sequences,)\n",
    "            best_index = np.argmax(rewards)\n",
    "            return actions[best_index, 0, :]\n",
    "        elif self.mpc_strategy == \"cem\":\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid MPC strategy '{self.mpc_strategy}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_sampler = ConstantSampler(dt=0.05)\n",
    "env = PendulumEnv(\n",
    "    dt_sampler=dt_sampler\n",
    ")\n",
    "mb_agent = ODEAgent(\n",
    "    env=env,\n",
    "    hidden_dims=[128, 128, 128],\n",
    "    make_optimizer=lambda param_list: torch.optim.AdamW(param_list),\n",
    "    ensemble_size=10,\n",
    "    mpc_horizon_steps=100,\n",
    "    mpc_timestep=0.005,\n",
    "    mpc_strategy=\"random\",\n",
    "    mpc_num_action_sequences=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.random.uniform(\n",
    "    mb_agent.env.action_space.low,\n",
    "    mb_agent.env.action_space.high,\n",
    "    size=(mb_agent.mpc_num_action_sequences, mb_agent.mpc_horizon_steps, mb_agent.ac_dim),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 82.8017 s\n",
      "File: /tmp/ipykernel_186605/3267144233.py\n",
      "Function: evaluate_action_sequences at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def evaluate_action_sequences(agent, obs: np.ndarray, acs: np.ndarray):\n",
      "     2         1      13825.0  13825.0      0.0      with torch.no_grad():\n",
      "     3         1      24795.0  24795.0      0.0          obs = ptu.from_numpy(obs)\n",
      "     4         1        116.0    116.0      0.0          acs_np = acs\n",
      "     5         1      83303.0  83303.0      0.0          acs = ptu.from_numpy(acs)\n",
      "     6         1      24536.0  24536.0      0.0          times = torch.linspace(0, (agent.mpc_horizon_steps - 1) * agent.mpc_timestep, agent.mpc_horizon_steps, device=ptu.device)\n",
      "     7         1       6850.0   6850.0      0.0          reward_arr = np.zeros((agent.mpc_num_action_sequences, agent.ensemble_size))\n",
      "     8        11       2248.0    204.4      0.0          for n in range(agent.mpc_num_action_sequences):\n",
      "     9       110      34870.0    317.0      0.0              for i in range(agent.ensemble_size):\n",
      "    10       100     832289.0   8322.9      0.0                  ode_func = agent.ode_functions[i]\n",
      "    11       100    1429678.0  14296.8      0.0                  ode_func.update_action(acs[n, :, :], times)\n",
      "    12       100        8e+10    8e+08    100.0                  ode_out = odeint(ode_func, obs, times) # (steps, ob_dim)\n",
      "    13       100    6478946.0  64789.5      0.0                  rewards, _ = agent.env.get_reward(ptu.to_numpy(ode_out), acs_np[n, :, :])\n",
      "    14       100    3020976.0  30209.8      0.0                  avg_reward = np.mean(rewards)\n",
      "    15       100      68506.0    685.1      0.0                  reward_arr[n, i] = avg_reward\n",
      "    16         1      26776.0  26776.0      0.0          return np.mean(reward_arr, axis=1)"
     ]
    }
   ],
   "source": [
    "%lprun -f evaluate_action_sequences evaluate_action_sequences(mb_agent, ob, actions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs285_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
