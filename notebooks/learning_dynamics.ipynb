{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler\n",
    "from cs285.envs.pendulum.pendulum_env import PendulumEnv\n",
    "from cs285.envs.dt_sampler import ConstantSampler\n",
    "from cs285.infrastructure.replay_buffer import ReplayBufferTrajectories\n",
    "from cs285.infrastructure.utils import sample_n_trajectories, RandomPolicy\n",
    "from cs285.agents.ode_agent import ODEAgent\n",
    "from cs285.agents.nueral_ode import Base_NeuralODE, NeuralODE_Vanilla, Pendulum_True_Dynamics, NeuralODE_Augmented, NeuralODE_Latent_MLP, ODE_RNN\n",
    "from cs285.agents.utils import save_leaves, load_leaves\n",
    "from cs285.infrastructure import utils\n",
    "from typing import Callable, Optional, Tuple, Sequence\n",
    "import numpy as np\n",
    "import gym\n",
    "from cs285.infrastructure import pytorch_util as ptu\n",
    "from tqdm import trange\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import diffrax\n",
    "from diffrax import diffeqsolve, Dopri5\n",
    "import optax\n",
    "import pickle\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.47it/s]\n"
     ]
    }
   ],
   "source": [
    "dt_sampler = ConstantSampler(dt=0.05)\n",
    "env = PendulumEnv(\n",
    "    dt_sampler=dt_sampler\n",
    ")\n",
    "ac_dim = env.action_space.shape[0]\n",
    "ob_dim = env.observation_space.shape[0]\n",
    "replay_buffer = ReplayBufferTrajectories(seed=42)\n",
    "trajs, _ = sample_n_trajectories(env, RandomPolicy(env=env), ntraj=100, max_length=200, key=key)\n",
    "replay_buffer.add_rollouts(trajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "_neural_odes = {\n",
    "    \"vanilla\": NeuralODE_Vanilla,\n",
    "    \"pendulum_true_dynamics\": Pendulum_True_Dynamics,\n",
    "    \"augmented\": NeuralODE_Augmented,\n",
    "    \"latent_mlp\": NeuralODE_Latent_MLP,\n",
    "    \"ode_rnn\": ODE_RNN\n",
    "}\n",
    "\n",
    "\n",
    "def train(neural_ode_name, neural_ode_kwargs, optimizer_name, optimizer_kwargs, train_config, replay_buffer):\n",
    "    optimizer_class = getattr(optax, optimizer_name)\n",
    "    optimizer = optimizer_class(**optimizer_kwargs)\n",
    "    neural_ode = _neural_odes[neural_ode_name](**neural_ode_kwargs)\n",
    "    opt_state = optimizer.init(eqx.filter(neural_ode, eqx.is_array))\n",
    "    discount_array = train_config[\"discount\"] ** jnp.arange(train_config[\"ep_len\"])\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    @eqx.filter_value_and_grad\n",
    "    def get_loss_grad(neural_ode, obs, acs, times):\n",
    "        obs_pred = neural_ode.batched_pred(ob=obs[:, 0, :], acs=acs, times=times)\n",
    "        l2_losses = jnp.sum((obs - obs_pred) ** 2, axis=-1) # (batch_size, ep_len)\n",
    "        weighed_mse = jnp.mean(discount_array * l2_losses)\n",
    "        return weighed_mse\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def get_loss(neural_ode, obs, acs, times):\n",
    "        obs_pred = neural_ode.batched_pred(ob=obs[:, 0, :], acs=acs, times=times)\n",
    "        l2_losses = jnp.sum((obs - obs_pred) ** 2, axis=-1) # (batch_size, ep_len)\n",
    "        return jnp.mean(l2_losses) # without discount\n",
    "\n",
    "    def get_data():\n",
    "        traj = replay_buffer.sample_rollouts(batch_size=train_config[\"batch_size\"])\n",
    "        obs = utils.split_arr(np.array(traj[\"observations\"]), length=train_config[\"ep_len\"], stride=train_config[\"stride\"])\n",
    "        acs = utils.split_arr(np.array(traj[\"actions\"]), length=train_config[\"ep_len\"], stride=train_config[\"stride\"])\n",
    "        dts = utils.split_arr(np.array(traj[\"dts\"])[..., np.newaxis], length=train_config[\"ep_len\"], stride=train_config[\"stride\"]).squeeze(-1)\n",
    "        batch_size, num_splitted, train_ep_len, ob_dim = obs.shape\n",
    "        ac_dim = acs.shape[-1]\n",
    "        obs = jnp.array(obs).reshape(batch_size * num_splitted, train_ep_len, ob_dim)\n",
    "        acs = jnp.array(acs).reshape(batch_size * num_splitted, train_ep_len, ac_dim)\n",
    "        times = jnp.cumsum(dts, axis=-1).reshape(batch_size * num_splitted, train_ep_len)\n",
    "        return obs, acs, times\n",
    "\n",
    "    losses = []\n",
    "    for step in trange(train_config[\"steps\"]):\n",
    "        obs, acs, times = get_data()\n",
    "        loss, grad = get_loss_grad(neural_ode, obs, acs, times)\n",
    "        updates, opt_state = optim.update(grad, opt_state, neural_ode)\n",
    "        neural_ode = eqx.apply_updates(neural_ode, updates)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    plt.plot(np.arange(len(losses)), losses)\n",
    "    return neural_ode, losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "neural_ode_name = \"vanilla\"\n",
    "neural_ode_kwargs = {\n",
    "    \"ode_dt0\": 0.005,\n",
    "    \"mlp_dynamics_setup\": {\n",
    "        \"hidden_size\":128,\n",
    "        \"num_layers\":4,\n",
    "        \"activation\":\"tanh\",\n",
    "        \"output_activation\":\"identity\"\n",
    "    },\n",
    "    \"ac_dim\": ac_dim,\n",
    "    \"ob_dim\": ob_dim,\n",
    "    \"key\": key\n",
    "}\n",
    "optimizer_name = \"adamw\"\n",
    "optimizer_kwargs = {\"learning_rate\": 1e-3}\n",
    "training_config = {\n",
    "    \"batch_size\": 64,\n",
    "    \"steps\": 1000,\n",
    "    \"ep_len\": 20,\n",
    "    \"stride\": 1,\n",
    "    \"discount\": 1.0,\n",
    "}\n",
    "neural_ode, losses = train(neural_ode_name, neural_ode_kwargs, optimizer_name, optimizer_kwargs, training_config, replay_buffer)\n",
    "save_leaves(nueral_ode, \"neural_ode_expr_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs285_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
