{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler\n",
    "from cs285.envs.pendulum.pendulum_env import PendulumEnv\n",
    "from cs285.envs.dt_sampler import ConstantSampler\n",
    "from cs285.infrastructure.replay_buffer import ReplayBufferTrajectories\n",
    "from cs285.infrastructure.utils import sample_n_trajectories, RandomPolicy\n",
    "from cs285.agents.ode_agent import ODEAgent\n",
    "from cs285.agents.utils import save_leaves, load_leaves\n",
    "from cs285.infrastructure import utils\n",
    "from typing import Callable, Optional, Tuple, Sequence\n",
    "import numpy as np\n",
    "import gym\n",
    "from cs285.infrastructure import pytorch_util as ptu\n",
    "from tqdm import trange\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import diffrax\n",
    "from diffrax import diffeqsolve, Dopri5\n",
    "import optax\n",
    "import pickle\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:17<00:00,  5.06it/s]\n"
     ]
    }
   ],
   "source": [
    "dt_sampler = ConstantSampler(dt=0.05)\n",
    "env = PendulumEnv(\n",
    "    dt_sampler=dt_sampler\n",
    ")\n",
    "mpc_dt_sampler = ConstantSampler(dt=0.05)\n",
    "agent_key, new_agent_key = jax.random.split(key)\n",
    "neural_ode_name = \"vanilla\"\n",
    "neural_ode_kwargs = {\n",
    "    \"ode_dt0\": 0.005,\n",
    "    \"mlp_dynamics_setup\": {\n",
    "        \"hidden_size\":128,\n",
    "        \"num_layers\":4,\n",
    "        \"activation\":\"tanh\",\n",
    "        \"output_activation\":\"identity\"\n",
    "    }\n",
    "}\n",
    "optimizer_name = \"adamw\"\n",
    "optimizer_kwargs = {\"learning_rate\": 1e-3}\n",
    "mb_agent = ODEAgent(\n",
    "    env=env,\n",
    "    key=agent_key,\n",
    "    neural_ode_name=neural_ode_name,\n",
    "    neural_ode_kwargs=neural_ode_kwargs,\n",
    "    optimizer_name=optimizer_name,\n",
    "    optimizer_kwargs=optimizer_kwargs,\n",
    "    ensemble_size=10,\n",
    "    train_discount=1,\n",
    "    mpc_horizon_steps=20,\n",
    "    mpc_dt_sampler=mpc_dt_sampler,\n",
    "    mpc_strategy=\"cem\",\n",
    "    mpc_discount=0.9,\n",
    "    mpc_num_action_sequences=1000,\n",
    "    cem_num_iters=4,\n",
    "    cem_num_elites=5,\n",
    "    cem_alpha=1,\n",
    ")\n",
    "replay_buffer = ReplayBufferTrajectories(seed=42)\n",
    "trajs, _ = sample_n_trajectories(env, RandomPolicy(env=env), ntraj=1000, max_length=200, key=key)\n",
    "replay_buffer.add_rollouts(trajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open(\"random_replay_buffer\", \"wb\") as f:\n",
    "    pickle.dump(replay_buffer, f)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_ep_len = 20\n",
    "train_stride = 1\n",
    "train_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [2:30:35<00:00, 90.36s/it]  \n"
     ]
    }
   ],
   "source": [
    "all_losses = []\n",
    "for _ in trange(train_steps, dynamic_ncols=True):\n",
    "    step_losses = []\n",
    "    for i in range(mb_agent.ensemble_size):\n",
    "        traj = replay_buffer.sample_rollouts(batch_size=batch_size)\n",
    "        obs = utils.split_arr(np.array(traj[\"observations\"]), length=train_ep_len, stride=train_stride)\n",
    "        acs = utils.split_arr(np.array(traj[\"actions\"]), length=train_ep_len, stride=train_stride)\n",
    "        dts = utils.split_arr(np.array(traj[\"dts\"])[..., np.newaxis], length=train_ep_len, stride=train_stride).squeeze(-1)\n",
    "        batch_size, num_splitted, train_ep_len, ob_dim = obs.shape\n",
    "        ac_dim = acs.shape[-1]\n",
    "        obs = jnp.array(obs).reshape(batch_size * num_splitted, train_ep_len, ob_dim)\n",
    "        acs = jnp.array(acs).reshape(batch_size * num_splitted, train_ep_len, ac_dim)\n",
    "        times = jnp.cumsum(dts, axis=-1).reshape(batch_size * num_splitted, train_ep_len)\n",
    "        loss = mb_agent.batched_update(\n",
    "            i=i,\n",
    "            obs=obs, \n",
    "            acs=acs, \n",
    "            times=times\n",
    "        )\n",
    "        step_losses.append(loss)\n",
    "    all_losses.append(np.mean(step_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_leaves(mb_agent, \"vanilla_trained_on_100_random_steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs285_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
